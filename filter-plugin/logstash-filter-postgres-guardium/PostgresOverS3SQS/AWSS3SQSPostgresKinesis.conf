input {
      s3_sqs {
        queue_url => "<queue_url>"
        region => "<region>"
        access_key_id => "<access_key_id>"
        secret_access_key => "<secret_access_key>"
        role_arn => "<role_arn>" # Leave empty if not using role-based access
        max_messages => <max_messages>
        wait_time => <wait_time> # Must be >= 0 and <= 20,
        polling_frequency => <polling_frequency>
        type => "<type>"
        add_field => { "account_id" => "<Enter aws account id>" }
      }
}

filter{

    if [type] == "Postgres" {

    # Step 1: Parse the JSON message from S3 event from cloudwatch
    json {
      source => "message"
      target => "parsed_message"
      remove_field => ["message"]
    }

    # Step 2: Split logEvents array into separate events
    split {
      field => "[parsed_message][logEvents]"
    }

    # Step 3: Extract each log message and promote to top-level [message]
    mutate {
      rename => { "[parsed_message][logEvents][message]" => "message" }
      add_field => {
        "logGroup"  => "%{[parsed_message][logGroup]}"
        "logStream" => "%{[parsed_message][logStream]}"
      }
    }

    # Step 4: Drop known noise events based on [message] content
    if [message] =~ /(pg_catalog|pg_attrdef|pg_class|pg_namespace)/ {
      drop { }
    }

    # Step 5: Parse message into fields using grok
    grok {
      match => {
        "message" => [

          # AUDIT log line with full_sql_query possibly quoted
          "%{TIMESTAMP_ISO8601:timestamp} UTC:%{IP:client_ip}\(%{INT:port}\):%{USERNAME:db_user}@%{DATA:db_name}:\[%{INT:pid}\]:%{WORD:log_level}:\s+AUDIT:\s+%{WORD:session_type},%{INT:statement_id},%{INT:substatement_id},%{WORD:command_class},%{DATA:command},%{DATA:object_type},%{DATA:object_name},(?:(?:\"%{GREEDYDATA:full_sql_query}\")|%{GREEDYDATA:full_sql_query}),%{GREEDYDATA:extra_info}",

          # STATEMENT logs
          "%{TIMESTAMP_ISO8601:timestamp} UTC:%{IP:client_ip}\(%{INT:client_port}\):%{USERNAME:db_user}@%{DATA:database}:\[%{INT:pid}\]:STATEMENT:\s+%{GREEDYDATA:full_sql_query}",

          # FAILED_CONNECT logs
          "%{TIMESTAMP_ISO8601:timestamp} UTC:%{IP:client_ip}\(%{NUMBER:client_port}\):%{USERNAME:db_user}@%{WORD:db_name}:\[%{NUMBER:session_id}\]:%{WORD:log_level}:\s+%{GREEDYDATA:full_sql_query}"

        ]
      }
    }

    # Step 6:Drop events that couldn't be parsed by grok
    if "_grokparsefailure" in [tags] {
        drop { }
    }

    # Step 7: Run Guardium plugin
    s3sqs_postgresql_guardium_plugin_filter { }

	# Step 8: Retain only processed GuardRecord
	prune {
	   whitelist_names => ["GuardRecord"]
	}
  }
}